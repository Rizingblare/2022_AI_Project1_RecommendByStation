{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f30a427d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pnu\\AppData\\Local\\Temp\\ipykernel_1880\\1353146049.py:194: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['역명'] = df['역명'].str.replace('역','').str.replace(r\"\\(.*\\)\",\"\")\n",
      "C:\\Users\\pnu\\AppData\\Local\\Temp\\ipykernel_1880\\1353146049.py:195: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['영문'] = df['영문'].str.replace(r\"[ .]\",\"\")\n",
      "C:\\Users\\pnu\\AppData\\Local\\Temp\\ipykernel_1880\\1353146049.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(DRIVER_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토성 Toseong\n",
      "50\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "_2bgjK \n",
      "this is not last page.\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "_2bgjK \n",
      "this is not last page.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 187>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kor,eng \u001b[38;5;129;01min\u001b[39;00m stationList:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# 현재 경로 내에 이미 크롤링한 파일이 있으면 continue\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (eng \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m dirList: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     \u001b[43mcollectFamousStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkor\u001b[49m\u001b[43m,\u001b[49m\u001b[43meng\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36mcollectFamousStore\u001b[1;34m(kor, eng)\u001b[0m\n\u001b[0;32m    175\u001b[0m keyword \u001b[38;5;241m=\u001b[39m kor \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m역맛집\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    177\u001b[0m targetBrowser \u001b[38;5;241m=\u001b[39m openTargetBrowser(keyword)\n\u001b[1;32m--> 179\u001b[0m targetList \u001b[38;5;241m=\u001b[39m \u001b[43mnavigatingPage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargetBrowser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m resultDF \u001b[38;5;241m=\u001b[39m ratingData(targetList)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# 엑셀에서 한글이 깨지지 않는 'utf-8-sig' 인코딩으로 csv 파일 추출\u001b[39;00m\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36mnavigatingPage\u001b[1;34m(browser)\u001b[0m\n\u001b[0;32m    132\u001b[0m         outList\u001b[38;5;241m.\u001b[39mappend([name, score, img, visitNum, blogNum])\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# 탐색이 끝난 후 다음 페이지로 이동\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43misLastPage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outList\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36misLastPage\u001b[1;34m(browser)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis is not last page.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m     nextBtn\u001b[38;5;241m.\u001b[39mclick()\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# class명이 \"_2bgjK _34lTS\"이면 마지막 페이지이므로 반복문 종료\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "DRIVER_PATH = './chromedriver.exe'\n",
    "BASE_URL = 'https://map.naver.com/v5/search/'\n",
    "\n",
    "def openTargetBrowser(keyword):\n",
    "    \n",
    "    # 키워드를 URL 형식으로 변환\n",
    "    encText = urllib.parse.quote(keyword)\n",
    "    url = BASE_URL + encText\n",
    "    \n",
    "    # selenium 브라우저로 해당 URL 접속\n",
    "    browser = webdriver.Chrome(DRIVER_PATH)\n",
    "    time.sleep(2)\n",
    "    browser.get(url)\n",
    "\n",
    "    # 필요한 정보가 있는 iframe 페이지에 name 속성명을 통한 접근\n",
    "    browser.switch_to.frame('searchIframe')\n",
    "    time.sleep(2)\n",
    "    \n",
    "    return browser\n",
    "\n",
    "def scrollingPage(browser):\n",
    "    # 스크롤을 하면 추가되는 <li> 항목을 모두 가져오기 위한 div 스크롤 조작\n",
    "    container = browser.find_element('id','_pcmap_list_scroll_container')\n",
    "    init = 3000\n",
    "    \n",
    "    for i in range(3):\n",
    "        init += i*1000\n",
    "        browser.execute_script(f\"arguments[0].scrollBy(0, {init})\", container)                                \n",
    "        time.sleep(2)\n",
    "        \n",
    "    return browser\n",
    "\n",
    "def splitData(kind, info):\n",
    "    kindInfo = {'blog':'블로그리뷰','visit':'방문자리뷰'}\n",
    "    # 블로그리뷰 를 기준으로 split한 리스트의 길이가 1이면\n",
    "    # 블로그리뷰에 대한 정보가 없는 것이므로 0을 저장\n",
    "    if len(info.split( kindInfo[kind] ))== 1:\n",
    "        return None, info\n",
    "    else:\n",
    "        info = info.split( kindInfo[kind] )\n",
    "        num = int(info[-1].replace(',',''))\n",
    "        \n",
    "        # split된 텍스트 중 나머지 정보가 담긴 텍스트로 이동\n",
    "        return num, info[0]\n",
    "\n",
    "def splitReviewNum(info):\n",
    "    if info:\n",
    "        info = info.text\n",
    "        \n",
    "        blogNum, nextInfo = splitData(\"blog\", info)\n",
    "        visitNum, usedInfo = splitData(\"visit\", nextInfo)\n",
    "    else:\n",
    "        blogNum = None\n",
    "        visitNum = None\n",
    "        \n",
    "    return visitNum, blogNum\n",
    "\n",
    "def isLastPage(browser):\n",
    "    # 이전 페이지, 5개의 페이지 번호, 다음 페이지 버튼으로 구성된\n",
    "    # 7개의 <a> 태그 중 다음 페이지 버튼인 마지막 <a> 태그 선택\n",
    "    nextBtn = browser.find_elements(By.CSS_SELECTOR,'div._2ky45 a')[-1]\n",
    "\n",
    "    # 해당 버튼의 class명 확인\n",
    "    btnClass = nextBtn.get_attribute(\"class\")\n",
    "    print(btnClass)\n",
    "\n",
    "    # 클래스명이 \"_2bgjK \"이면 (공백 포함 주의 !!)\n",
    "    # 마지막 페이지가 아니므로 다음 페이지로 이동\n",
    "    if btnClass == \"_2bgjK \":\n",
    "        print(\"this is not last page.\")\n",
    "        nextBtn.click()\n",
    "        time.sleep(2)\n",
    "        return False\n",
    "\n",
    "    # class명이 \"_2bgjK _34lTS\"이면 마지막 페이지이므로 반복문 종료\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def navigatingPage(browser):\n",
    "    # 데이터를 담을 리스트와 각 항목에 대한 접근을 확인하기 위한 cnt 변수 생성\n",
    "    outList = []\n",
    "    cnt = 0\n",
    "    \n",
    "    while True: \n",
    "        browser = scrollingPage(browser)\n",
    "        \n",
    "        # 스크롤 된 페이지 소스를 bs4 객체로 변환\n",
    "        htmlStr = browser.page_source\n",
    "        bs = BeautifulSoup(htmlStr,'html.parser')\n",
    "        \n",
    "        targetDiv = bs.select_one('div#_pcmap_list_scroll_container')\n",
    "        targets = targetDiv.select(\"li[class='_1EKsQ _12tNp']\")\n",
    "        \n",
    "        # 페이지당 50개인 <li> 항목을 모두 가져왔는지 확인 \n",
    "        print(len(targets))\n",
    "\n",
    "        for t in targets:\n",
    "            \n",
    "            # 접근 중인 항목 번호 \n",
    "            cnt += 1\n",
    "            print(cnt)\n",
    "            \n",
    "            # 점포명\n",
    "            name = t.select_one('span.place_bluelink').text\n",
    "\n",
    "            # 별점 (별점이 없으면 None을 저장)\n",
    "            score = t.select_one('em')\n",
    "            if score:\n",
    "                score = float(score.text)\n",
    "            else:\n",
    "                score = None\n",
    "            \n",
    "            # 썸네일 이미지\n",
    "            img = t.select_one('div.cb7hz')\n",
    "            if img:\n",
    "                img = img['style'].split('\"')[1]\n",
    "            else:\n",
    "                img = None\n",
    "            \n",
    "            # 영업 상태, 별점, 리뷰 등이 담겨있는 div 태그 텍스트\n",
    "            containerInfo = t.select_one('div._17H46')\n",
    "            visitNum, blogNum = splitReviewNum(containerInfo)\n",
    "            \n",
    "            outList.append([name, score, img, visitNum, blogNum])\n",
    "\n",
    "        # 탐색이 끝난 후 다음 페이지로 이동\n",
    "        if isLastPage(browser):\n",
    "            break\n",
    "            \n",
    "    return outList\n",
    "\n",
    "def ratingData(result):\n",
    "    df = pd.DataFrame(result,columns=['점포명','별점','이미지','방문자 리뷰 수', '블로그 리뷰 수'])\n",
    "\n",
    "    # 별점이나 방문자 리뷰 수, 블로그 리뷰 수 중 하나라도 결측값이 있는 레코드 삭제\n",
    "    df = df.dropna(how='any', subset=['별점','방문자 리뷰 수','블로그 리뷰 수'])\n",
    "    \n",
    "    # Pandas의 qcut() 함수를 이용해 리뷰 수 분포에 따른 구간 산출\n",
    "    # 동점이 많은 낮은 구간에서 구간의 중복이 발생하는 것에 대해 rank 함수를 사용한 순위 부여\n",
    "    # 첫번째 값 (method='first') : 동점 관측치 중에서 데이터 상에서 먼저 나타나는 관측치부터 순위 부여를 부여하는 rank 함수의 옵션\n",
    "    df['방문자 리뷰 구간'] = pd.qcut(df['방문자 리뷰 수'].rank(method = 'first'),10, labels=False)\n",
    "    df['블로그 리뷰 구간'] = pd.qcut(df['블로그 리뷰 수'].rank(method = 'first'),10, labels=False)\n",
    "\n",
    "    display(df.describe())\n",
    "    \n",
    "    # 방문자 리뷰와 블로그 리뷰의 중요도에 따른 가중치 부여\n",
    "    visitWeight = 0.2\n",
    "    blogWeight = 0.8\n",
    "    totalScore = df['별점'] + (((df['방문자 리뷰 구간'] + 1) / 10) * visitWeight) + (((df['블로그 리뷰 구간'] + 1) / 10) * blogWeight) + 4\n",
    "    df['평점'] = round(totalScore, 2)\n",
    "    \n",
    "    # 데이터형 정제\n",
    "    df = df.astype({\n",
    "        '방문자 리뷰 수' : 'int',\n",
    "        '블로그 리뷰 수' : 'int',\n",
    "    })\n",
    "    \n",
    "    # 평점 기준 상위 5개 데이터 확인\n",
    "    display(df.nlargest(5,'평점', keep='first'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "def collectFamousStore(kor,eng):\n",
    "    # 입력받은 지하철역 키워드 생성\n",
    "    print(kor, eng)\n",
    "    keyword = kor + \"역맛집\"\n",
    "    \n",
    "    targetBrowser = openTargetBrowser(keyword)\n",
    "    \n",
    "    targetList = navigatingPage(targetBrowser)\n",
    "    \n",
    "    resultDF = ratingData(targetList)\n",
    "\n",
    "    # 엑셀에서 한글이 깨지지 않는 'utf-8-sig' 인코딩으로 csv 파일 추출\n",
    "\n",
    "    resultDF.to_csv(f\"{eng}.csv\",encoding='utf-8-sig')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "# 지하철역명 입력 후 collectFamousStore 함수로 전달 \n",
    "#     collectFamousStore(input())\n",
    "\n",
    "    df = pd.read_csv('./부산교통공사_도시철도역정보_20211020.csv', encoding='cp949')\n",
    "    df = df.loc[df['역코드'] < 200,['역명','영문']]\n",
    "    df['역명'] = df['역명'].str.replace('역','').str.replace(r\"\\(.*\\)\",\"\")\n",
    "    df['영문'] = df['영문'].str.replace(r\"[ .]\",\"\")\n",
    "    stationList = df.to_numpy().tolist()\n",
    "    \n",
    "    dirList = os.listdir()\n",
    "    \n",
    "    for kor,eng in stationList:\n",
    "        # 현재 경로 내에 이미 크롤링한 파일이 있으면 continue\n",
    "        if (eng + '.csv') in dirList: continue\n",
    "        collectFamousStore(kor,eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685ea5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
